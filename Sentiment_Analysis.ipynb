{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification\n",
    "\n",
    "Instead of using an unsupervised method like VADER for sentiment analysis, I will create a model that will try to predict the sentiment of a review with supervised learning methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import spacy\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('data/processed_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cleaned_reviews.csv', converters = {'cleaned_text_sent': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 133546 entries, 0 to 133545\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   reviews            133546 non-null  object\n",
      " 1   sentiment          133546 non-null  int64 \n",
      " 2   cleaned_text       133546 non-null  object\n",
      " 3   dominant_topic     133546 non-null  int64 \n",
      " 4   cleaned_text_sent  133546 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>cleaned_text_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get the SportaPros instead.  They look better,...</td>\n",
       "      <td>1</td>\n",
       "      <td>['instead', 'look', 'well', 'wear', 'street', ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[sportapros, instead, look, well, wear, street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've been looking for a lighter alternative to...</td>\n",
       "      <td>1</td>\n",
       "      <td>['look', 'light', 'alternative', 'absolutely',...</td>\n",
       "      <td>2</td>\n",
       "      <td>[look, light, alternative, absolutely, perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The finest headphones available. You can spend...</td>\n",
       "      <td>1</td>\n",
       "      <td>['fine', 'headphone', 'available', 'spend', 'v...</td>\n",
       "      <td>2</td>\n",
       "      <td>[fine, headphone, available, spend, vast, amou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd pair of these I've purchased.  My wife has...</td>\n",
       "      <td>1</td>\n",
       "      <td>['pair', 'purchase', 'wife', 'pair', 'pair', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>[rd, pair, purchase, wife, pair, pair, glove, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My old Koss Porta Pros finally got beat to dea...</td>\n",
       "      <td>1</td>\n",
       "      <td>['old', 'finally', 'get', 'beat', 'death', 'ye...</td>\n",
       "      <td>4</td>\n",
       "      <td>[old, koss, porta, pros, finally, get, beat, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment  \\\n",
       "0  Get the SportaPros instead.  They look better,...          1   \n",
       "1  I've been looking for a lighter alternative to...          1   \n",
       "2  The finest headphones available. You can spend...          1   \n",
       "3  3rd pair of these I've purchased.  My wife has...          1   \n",
       "4  My old Koss Porta Pros finally got beat to dea...          1   \n",
       "\n",
       "                                        cleaned_text  dominant_topic  \\\n",
       "0  ['instead', 'look', 'well', 'wear', 'street', ...               4   \n",
       "1  ['look', 'light', 'alternative', 'absolutely',...               2   \n",
       "2  ['fine', 'headphone', 'available', 'spend', 'v...               2   \n",
       "3  ['pair', 'purchase', 'wife', 'pair', 'pair', '...               3   \n",
       "4  ['old', 'finally', 'get', 'beat', 'death', 'ye...               4   \n",
       "\n",
       "                                   cleaned_text_sent  \n",
       "0  [sportapros, instead, look, well, wear, street...  \n",
       "1  [look, light, alternative, absolutely, perfect...  \n",
       "2  [fine, headphone, available, spend, vast, amou...  \n",
       "3  [rd, pair, purchase, wife, pair, pair, glove, ...  \n",
       "4  [old, koss, porta, pros, finally, get, beat, d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.766582\n",
       "0    0.233418\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning for sentiment analysis\n",
    "\n",
    "I will need to modify the text cleaning process for sentiment analysis. Negation words such as not and no are usually removed by standard stop word lists. These negations may not have made a big difference for topic modeling, but they can change the sentiment of a statement depending on if they are removed or not. For example the phrase \"Not great, do not buy\" is a negative statement. But after removal of standard stop words the statment will be \"great buy\", which can be seen as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for words to remove from stop_words\n",
    "stop_list = ['cannot', 'not', 'nor', 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in stop_list:\n",
    "    # Add the word to the set of stop words.\n",
    "    nlp.Defaults.stop_words.remove(item)\n",
    "    \n",
    "    # Set the stop_word tag on the lexeme\n",
    "    nlp.vocab[item].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another step I will be adding is to expand conractions. This will allow me to preserve 'not' tokens. For this i will be using the contractions library that expands contractions with below simple code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'will not cannot do not'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions.fix('wont cant dont')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Replace &nbsp; with regular space\n",
    "    text = text.replace(\"&nbsp;\", \" \")\n",
    "    # Remove HTML tags and attributes\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Remove line breaks and extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    # Remove numbers and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Convert to lowercase and remove leading/trailing white space\n",
    "    # Tokenize and lemmatize, keep words with length greater than 1\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_.lower().strip() for token in doc if not token.is_punct and not token.is_stop and len(token) > 1]\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I got these headphones as a xmas for my wife (yeah for me too). I own multiple pairs of corded headphones and one other pair of cheap bluetooth headphones (Kinivo BTH240). My daily go to headphones are a pair of Sennheiser hd 280 pro cans and I have a pair of Audio-Technica ATH-M30 that I use at work.\\n\\nRatings:\\n\\nSound: 8/10\\n\\nThe sound is fairly detailed and well balanced. The bass end is not overpowering nor underwhelming. Midrange is clear and distinct. High end has detail and it is not too tinny. YMMV. I would say, for the headphones I use, the sound reproduction is somewhere between my Audio-Technica ATH-M30 but not quite as good as my Sennheiser hd 280. Which is on par for the price range they are in. Come on people, stop comparing these to headphones that cost 3-5 times as much.\\n\\nComfort: 10/10\\n\\nThese fit over my ears well and these may very well be the most comfortable headphones I presently own. Most headphones I wear do not bother me much and these are no exception.\\n\\nBuild quality: 10/10\\n\\nThese headphones have a solid feel to them; a lot like a high end Benz car door. Only time will tell how durable they will be but they give me a lot of confidence.\\n\\nNoise cancellation: 8/10\\n\\nI have read other reviews and I am astounded people would be audacious enough to compare these headphones to Bose QC25 or 35s. This is frankly ridiculous. I started with a 7 then moved it to 7.5 but really forgive me in giving this 8 out of 10. For the price range, the sound quality with NC is well above average; just below outstanding. Any active noise cancellation will color the sound. This is just physics. These headphones do a great job of delivering great sound while reducing the ambient low end noise without coloring the music too much. To experiment, take these headphones into your car and play no music in them but turn on the car with the fan on. Turn the noise cancellation on and off and on again. The low end frequencies will be absent while higher frequencies still remain. I use Bose A20 aviation headsets which have far superior noise reduction but the noise cancellation performance above 500 hz would only be marginally different. I would assume the QC25 would be the same and I wouldn't spend another $200 for that minute performance difference.\\n\\nWireless performance: 9/10\\n\\nI have been really impressed by the bluetooth performance. I own a pair of $25 bluetooth headphones. I can't leave the room without dropping. The range is much better. Of course bluetooth is really meant for LOS (line of sight) and it would be asking a lot of any bluetooth device to successfully transmit thru a wall in another room. But these did fine in nLOS (near line of sight) with a distance of 25 ft. Also these did very well on a phone call. The other person couldn't even tell I was on a bluetooth headset.\\n\\nPerceived Value: 9/10\\n\\nFor one Ben Franklin, I am well please with the value delivered thus far. I am reasonably confident these headphones will last for some time. If you are looking for an all purpose bluetooth headphones, you can't go wrong with these headphones. I highly recommend them. Love these cordless cans!\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample review to test clean function\n",
    "data.reviews[132512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get',\n",
       " 'headphone',\n",
       " 'xma',\n",
       " 'wife',\n",
       " 'yeah',\n",
       " 'multiple',\n",
       " 'pair',\n",
       " 'cord',\n",
       " 'headphone',\n",
       " 'pair',\n",
       " 'cheap',\n",
       " 'bluetooth',\n",
       " 'headphone',\n",
       " 'kinivo',\n",
       " 'bth',\n",
       " 'daily',\n",
       " 'headphone',\n",
       " 'pair',\n",
       " 'sennheiser',\n",
       " 'hd',\n",
       " 'pro',\n",
       " 'can',\n",
       " 'pair',\n",
       " 'audiotechnica',\n",
       " 'athm',\n",
       " 'use',\n",
       " 'work',\n",
       " 'ratings',\n",
       " 'sound',\n",
       " 'sound',\n",
       " 'fairly',\n",
       " 'detailed',\n",
       " 'balance',\n",
       " 'bass',\n",
       " 'end',\n",
       " 'overpower',\n",
       " 'underwhelme',\n",
       " 'midrange',\n",
       " 'clear',\n",
       " 'distinct',\n",
       " 'high',\n",
       " 'end',\n",
       " 'detail',\n",
       " 'tinny',\n",
       " 'ymmv',\n",
       " 'headphone',\n",
       " 'use',\n",
       " 'sound',\n",
       " 'reproduction',\n",
       " 'audiotechnica',\n",
       " 'athm',\n",
       " 'good',\n",
       " 'sennheiser',\n",
       " 'hd',\n",
       " 'par',\n",
       " 'price',\n",
       " 'range',\n",
       " 'come',\n",
       " 'people',\n",
       " 'stop',\n",
       " 'compare',\n",
       " 'headphone',\n",
       " 'cost',\n",
       " 'time',\n",
       " 'comfort',\n",
       " 'fit',\n",
       " 'ear',\n",
       " 'comfortable',\n",
       " 'headphone',\n",
       " 'presently',\n",
       " 'headphone',\n",
       " 'wear',\n",
       " 'bother',\n",
       " 'exception',\n",
       " 'build',\n",
       " 'quality',\n",
       " 'headphone',\n",
       " 'solid',\n",
       " 'feel',\n",
       " 'lot',\n",
       " 'like',\n",
       " 'high',\n",
       " 'end',\n",
       " 'benz',\n",
       " 'car',\n",
       " 'door',\n",
       " 'time',\n",
       " 'tell',\n",
       " 'durable',\n",
       " 'lot',\n",
       " 'confidence',\n",
       " 'noise',\n",
       " 'cancellation',\n",
       " 'read',\n",
       " 'review',\n",
       " 'astounded',\n",
       " 'people',\n",
       " 'audacious',\n",
       " 'compare',\n",
       " 'headphone',\n",
       " 'bose',\n",
       " 'qc',\n",
       " 'frankly',\n",
       " 'ridiculous',\n",
       " 'start',\n",
       " 'move',\n",
       " 'forgive',\n",
       " 'give',\n",
       " 'price',\n",
       " 'range',\n",
       " 'sound',\n",
       " 'quality',\n",
       " 'nc',\n",
       " 'average',\n",
       " 'outstanding',\n",
       " 'active',\n",
       " 'noise',\n",
       " 'cancellation',\n",
       " 'color',\n",
       " 'sound',\n",
       " 'physics',\n",
       " 'headphone',\n",
       " 'great',\n",
       " 'job',\n",
       " 'deliver',\n",
       " 'great',\n",
       " 'sound',\n",
       " 'reduce',\n",
       " 'ambient',\n",
       " 'low',\n",
       " 'end',\n",
       " 'noise',\n",
       " 'color',\n",
       " 'music',\n",
       " 'experiment',\n",
       " 'headphone',\n",
       " 'car',\n",
       " 'play',\n",
       " 'music',\n",
       " 'turn',\n",
       " 'car',\n",
       " 'fan',\n",
       " 'turn',\n",
       " 'noise',\n",
       " 'cancellation',\n",
       " 'low',\n",
       " 'end',\n",
       " 'frequency',\n",
       " 'absent',\n",
       " 'high',\n",
       " 'frequency',\n",
       " 'remain',\n",
       " 'use',\n",
       " 'bose',\n",
       " 'aviation',\n",
       " 'headset',\n",
       " 'far',\n",
       " 'superior',\n",
       " 'noise',\n",
       " 'reduction',\n",
       " 'noise',\n",
       " 'cancellation',\n",
       " 'performance',\n",
       " 'hz',\n",
       " 'marginally',\n",
       " 'different',\n",
       " 'assume',\n",
       " 'qc',\n",
       " 'spend',\n",
       " 'minute',\n",
       " 'performance',\n",
       " 'difference',\n",
       " 'wireless',\n",
       " 'performance',\n",
       " 'impress',\n",
       " 'bluetooth',\n",
       " 'performance',\n",
       " 'pair',\n",
       " 'bluetooth',\n",
       " 'headphone',\n",
       " 'leave',\n",
       " 'room',\n",
       " 'drop',\n",
       " 'range',\n",
       " 'well',\n",
       " 'course',\n",
       " 'bluetooth',\n",
       " 'mean',\n",
       " 'los',\n",
       " 'line',\n",
       " 'sight',\n",
       " 'ask',\n",
       " 'lot',\n",
       " 'bluetooth',\n",
       " 'device',\n",
       " 'successfully',\n",
       " 'transmit',\n",
       " 'wall',\n",
       " 'room',\n",
       " 'fine',\n",
       " 'nlos',\n",
       " 'near',\n",
       " 'line',\n",
       " 'sight',\n",
       " 'distance',\n",
       " 'ft',\n",
       " 'phone',\n",
       " 'person',\n",
       " 'tell',\n",
       " 'bluetooth',\n",
       " 'headset',\n",
       " 'perceive',\n",
       " 'value',\n",
       " 'ben',\n",
       " 'franklin',\n",
       " 'value',\n",
       " 'deliver',\n",
       " 'far',\n",
       " 'reasonably',\n",
       " 'confident',\n",
       " 'headphone',\n",
       " 'time',\n",
       " 'look',\n",
       " 'purpose',\n",
       " 'bluetooth',\n",
       " 'headphone',\n",
       " 'wrong',\n",
       " 'headphone',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'love',\n",
       " 'cordless',\n",
       " 'can']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(data.reviews[132512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text_sent'] = data.reviews.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('data/cleaned_reviews.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my features are text data, before I can input into any models I will need to vectorize the text to be represented as numbers. I will test out various vectorizers and classification models to find the best performing model. \n",
    "\n",
    "Vectorizers:\n",
    "* CountVectorizer\n",
    "* TfidfVectorizer\n",
    "* Word2Vec\n",
    "* Pre-trained Glove\n",
    "\n",
    "Classification Algorithms:\n",
    "* Logistic Regression\n",
    "* Naive Bayes\n",
    "* Random Forest\n",
    "* LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Seperating target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing sentiment to numerical values\n",
    "data.replace({'sentiment':{'Negative': 0, 'Positve': 1}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.766582\n",
       "0    0.233418\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.cleaned_text_sent\n",
    "y = data.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "Splitting data to train and test sets with stratify to keep class percentages similar in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106836,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26710,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.766586\n",
       "0    0.233414\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.766567\n",
       "0    0.233433\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "For our baseline model I will use logistic regression / countvectorizer and optimize for f1 score due to imbalanced dataset, as this metric will have a good balance of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer\n",
    "\n",
    "Vectorizer used to create a bag of words model. Will create a matrix will all the words avaliable in the documents and the number of times they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer with unigrams and bigrams\n",
    "count_vect = CountVectorizer(ngram_range = (1,2), \n",
    "                             stop_words = None, \n",
    "                             tokenizer = dummy, \n",
    "                             preprocessor = dummy,\n",
    "                             min_df = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(min_df=10, ngram_range=(1, 2),\n",
       "                preprocessor=<function dummy at 0x000001E74594C430>,\n",
       "                tokenizer=<function dummy at 0x000001E74594C430>)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64601"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total vocabulary length\n",
    "len(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression(class_weight = 'balanced', solver = 'saga', max_iter = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_logr_model = Pipeline([\n",
    "    ('countvec', count_vect),\n",
    "    ('logreg', logr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "cv_logr = cross_validate(cv_logr_model, X_train, y_train, cv = 5, scoring = ['f1', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.DataFrame(columns=['Model', 'mean f1_score', 'std f1_score', 'mean precision', 'mean recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append({'Model': 'cv_logr_model',\n",
    "                      'mean f1_score': round(cv_logr['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(cv_logr['test_f1'].std(), 4),\n",
    "                      'mean precision': round(cv_logr['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(cv_logr['test_recall'].mean(), 4)}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mean f1_score</th>\n",
       "      <th>std f1_score</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_logr_model</td>\n",
       "      <td>0.9248</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  mean f1_score  std f1_score  mean precision  mean recall\n",
       "0  cv_logr_model         0.9248        0.0016          0.9352       0.9145"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_logr_hat = cross_val_predict(cv_logr_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, cv_logr_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent results for a baseline model. f1 score of 92% was obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvec',\n",
       "                 CountVectorizer(preprocessor=<function dummy at 0x000001E74594C430>,\n",
       "                                 tokenizer=<function dummy at 0x000001E74594C430>)),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000,\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07583987,  0.34361272,  0.25439821, ..., -0.00201732,\n",
       "        0.00045675,  0.03273963])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr_cv_model.steps[1][1].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9025</th>\n",
       "      <td>2.048368</td>\n",
       "      <td>charm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7129</th>\n",
       "      <td>1.973041</td>\n",
       "      <td>budge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>1.754057</td>\n",
       "      <td>ample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25102</th>\n",
       "      <td>1.722740</td>\n",
       "      <td>holy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45193</th>\n",
       "      <td>1.710818</td>\n",
       "      <td>remedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21980</th>\n",
       "      <td>1.705805</td>\n",
       "      <td>goggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19760</th>\n",
       "      <td>1.701909</td>\n",
       "      <td>fits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47154</th>\n",
       "      <td>1.696865</td>\n",
       "      <td>sanity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18104</th>\n",
       "      <td>1.691321</td>\n",
       "      <td>exceed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24866</th>\n",
       "      <td>1.691023</td>\n",
       "      <td>hint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features   names\n",
       "9025   2.048368   charm\n",
       "7129   1.973041   budge\n",
       "1886   1.754057   ample\n",
       "25102  1.722740    holy\n",
       "45193  1.710818  remedy\n",
       "21980  1.705805  goggle\n",
       "19760  1.701909    fits\n",
       "47154  1.696865  sanity\n",
       "18104  1.691321  exceed\n",
       "24866  1.691023    hint"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = logr_cv_model.steps[1][1].coef_[0]\n",
    "\n",
    "names = logr_cv_model['countvec'].get_feature_names()\n",
    "\n",
    "dff = pd.DataFrame({'features': features, 'names': names})\n",
    "\n",
    "dff.sort_values('features', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57560</th>\n",
       "      <td>-2.437693</td>\n",
       "      <td>unacceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14384</th>\n",
       "      <td>-2.157037</td>\n",
       "      <td>disappointing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8642</th>\n",
       "      <td>-2.083052</td>\n",
       "      <td>cease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47071</th>\n",
       "      <td>-2.081539</td>\n",
       "      <td>sam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32748</th>\n",
       "      <td>-2.050582</td>\n",
       "      <td>meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61790</th>\n",
       "      <td>-1.990861</td>\n",
       "      <td>womp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>-1.983314</td>\n",
       "      <td>defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14375</th>\n",
       "      <td>-1.983296</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62123</th>\n",
       "      <td>-1.930738</td>\n",
       "      <td>worse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58070</th>\n",
       "      <td>-1.926048</td>\n",
       "      <td>unimpressed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features          names\n",
       "57560 -2.437693   unacceptable\n",
       "14384 -2.157037  disappointing\n",
       "8642  -2.083052          cease\n",
       "47071 -2.081539            sam\n",
       "32748 -2.050582            meh\n",
       "61790 -1.990861           womp\n",
       "13300 -1.983314         defeat\n",
       "14375 -1.983296   disappointed\n",
       "62123 -1.930738          worse\n",
       "58070 -1.926048    unimpressed"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.sort_values('features', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(class_prior = [0.23, 0.77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mnb_model = Pipeline([\n",
    "    ('countvec', count_vect),\n",
    "    ('mnb', mnb)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mnb = cross_validate(cv_mnb_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append({'Model': 'cv_mnb_model',\n",
    "                      'mean f1_score': round(cv_mnb['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(cv_mnb['test_f1'].std(), 4),\n",
    "                      'mean precision': round(cv_mnb['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(cv_mnb['test_recall'].mean(), 4)}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mean f1_score</th>\n",
       "      <th>std f1_score</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_logr_model</td>\n",
       "      <td>0.9248</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_mnb_model</td>\n",
       "      <td>0.9173</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>0.9026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  mean f1_score  std f1_score  mean precision  mean recall\n",
       "0  cv_logr_model         0.9248        0.0016          0.9352       0.9145\n",
       "1   cv_mnb_model         0.9173        0.0012          0.9325       0.9026"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_mnb_hat = cross_val_predict(cv_mnb_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, cv_mnb_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rf_model = Pipeline([\n",
    "    ('countvec', count_vect),\n",
    "    ('rf', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-274-b13b122fac5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_rf_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \"\"\"\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_rf = cross_validate(cv_rf_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append({'Model': 'cv_rf_model',\n",
    "                      'mean f1_score': round(cv_rf['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(cv_rf['test_f1'].std(), 4),\n",
    "                      'mean precision': round(cv_rf['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(cv_rf['test_recall'].mean(), 4)}, ignore_index = True)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rf_hat = cross_val_predict(cv_rf_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, cv_rf_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvec',\n",
       "                 CountVectorizer(preprocessor=<function dummy at 0x000001E74594C430>,\n",
       "                                 tokenizer=<function dummy at 0x000001E74594C430>)),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(class_weight='balanced',\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_cv_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = rfc_cv_model.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = rfc_cv_model['countvec'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame({'features': features, 'names': names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22460</th>\n",
       "      <td>0.023896</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36781</th>\n",
       "      <td>0.021160</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45789</th>\n",
       "      <td>0.013824</td>\n",
       "      <td>return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31226</th>\n",
       "      <td>0.009296</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37550</th>\n",
       "      <td>0.007673</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41511</th>\n",
       "      <td>0.006662</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34269</th>\n",
       "      <td>0.006356</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22046</th>\n",
       "      <td>0.006323</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>0.006276</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18121</th>\n",
       "      <td>0.005911</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42292</th>\n",
       "      <td>0.005885</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>0.005413</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50730</th>\n",
       "      <td>0.005389</td>\n",
       "      <td>sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15918</th>\n",
       "      <td>0.005250</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52341</th>\n",
       "      <td>0.005247</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23840</th>\n",
       "      <td>0.005200</td>\n",
       "      <td>headphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61900</th>\n",
       "      <td>0.004883</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16450</th>\n",
       "      <td>0.004348</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.004189</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24719</th>\n",
       "      <td>0.003929</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features      names\n",
       "22460  0.023896      great\n",
       "36781  0.021160        not\n",
       "45789  0.013824     return\n",
       "31226  0.009296       love\n",
       "37550  0.007673         ok\n",
       "41511  0.006662       poor\n",
       "34269  0.006356      month\n",
       "22046  0.006323       good\n",
       "4159   0.006276        bad\n",
       "18121  0.005911  excellent\n",
       "42292  0.005885      price\n",
       "39997  0.005413    perfect\n",
       "50730  0.005389      sound\n",
       "15918  0.005250        ear\n",
       "52341  0.005247       stop\n",
       "23840  0.005200  headphone\n",
       "61900  0.004883       work\n",
       "16450  0.004348       easy\n",
       "1673   0.004189    amazing\n",
       "24719  0.003929     highly"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.sort_values('features', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "One way to focus on more meaningful terms is to use TF-IDF Vectorizer. TF-IDF scores give more importance to terms that appear frequently in a certain document, but less frequent in all other documents. TF-IDF scores will be lower for words that appear frequently in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1,2), \n",
    "                             stop_words = None, \n",
    "                             tokenizer = dummy, \n",
    "                             preprocessor = dummy,\n",
    "                             min_df = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total vocabulary length\n",
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logr_model = Pipeline([\n",
    "    ('tfidfvec', tfidf),\n",
    "    ('logreg', logr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logr = cross_validate(tfidf_logr_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append({'Model': 'tfidf_logr_model',\n",
    "                      'mean f1_score': round(tfidf_logr['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(tfidf_logr['test_f1'].std(), 4),\n",
    "                      'mean precision': round(tfidf_logr['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(tfidf_logr['test_recall'].mean(), 4)}, ignore_index = True)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logr_hat = cross_val_predict(tfidf_logr_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, tfidf_logr_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mnb_model = Pipeline([\n",
    "    ('tfidfvec', tfidf),\n",
    "    ('mnb', mnb)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mnb = cross_validate(tfidf_mnb_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mean f1_score</th>\n",
       "      <th>std f1_score</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_logreg_model</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_mnb_model</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv_rf_model</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_logreg_model</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.8681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_mnb_model</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  mean f1_score  std f1_score  mean precision  \\\n",
       "0     cv_logreg_model         0.9073        0.0019          0.9371   \n",
       "1        cv_mnb_model         0.9164        0.0017          0.8980   \n",
       "2         cv_rf_model         0.9103        0.0007          0.8421   \n",
       "3  tfidf_logreg_model         0.9055        0.0021          0.9463   \n",
       "4     tfidf_mnb_model         0.8748        0.0003          0.7778   \n",
       "\n",
       "   mean recall  \n",
       "0       0.8794  \n",
       "1       0.9355  \n",
       "2       0.9904  \n",
       "3       0.8681  \n",
       "4       0.9993  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = model_results.append({'Model': 'tfidf_mnb_model',\n",
    "                      'mean f1_score': round(tfidf_mnb['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(tfidf_mnb['test_f1'].std(), 4),\n",
    "                      'mean precision': round(tfidf_mnb['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(tfidf_mnb['test_recall'].mean(), 4)}, ignore_index = True)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mnb_hat = cross_val_predict(tfidf_mnb_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, tfidf_mnb_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_rf_model = Pipeline([\n",
    "    ('tfidfvec', tfidf),\n",
    "    ('rf', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_rf = cross_validate(tfidf_rf_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mean f1_score</th>\n",
       "      <th>std f1_score</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_logreg_model</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_mnb_model</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv_rf_model</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_logreg_model</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.8681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_mnb_model</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_rf_model</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.9894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  mean f1_score  std f1_score  mean precision  \\\n",
       "0     cv_logreg_model         0.9073        0.0019          0.9371   \n",
       "1        cv_mnb_model         0.9164        0.0017          0.8980   \n",
       "2         cv_rf_model         0.9103        0.0007          0.8421   \n",
       "3  tfidf_logreg_model         0.9055        0.0021          0.9463   \n",
       "4     tfidf_mnb_model         0.8748        0.0003          0.7778   \n",
       "5      tfidf_rf_model         0.9109        0.0003          0.8440   \n",
       "\n",
       "   mean recall  \n",
       "0       0.8794  \n",
       "1       0.9355  \n",
       "2       0.9904  \n",
       "3       0.8681  \n",
       "4       0.9993  \n",
       "5       0.9894  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = model_results.append({'Model': 'tfidf_rf_model',\n",
    "                      'mean f1_score': round(tfidf_rf['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(tfidf_rf['test_f1'].std(), 4),\n",
    "                      'mean precision': round(tfidf_rf['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(tfidf_rf['test_recall'].mean(), 4)}, ignore_index = True)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_rf_hat = cross_val_predict(tfidf_rf_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, tfidf_rf_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "The previous two vectorization strategies have only focused on term frequency. In order to try to capture semantic meaning of terms, we can use word embeddings. Using Word2Vec we can create word vector embeddings that can try to capture semantic relationships between words, if given enough data to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a w2v model\n",
    "model = Word2Vec(X_train, size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106836"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total reviews in train set\n",
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37519025, 44748080)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.train(X_train, total_examples=model.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word vectors\n",
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 0.7894223928451538),\n",
       " ('excellent', 0.7781077027320862),\n",
       " ('fantastic', 0.7535078525543213),\n",
       " ('awesome', 0.7460759878158569),\n",
       " ('amazing', 0.6775975227355957),\n",
       " ('nice', 0.6653569936752319),\n",
       " ('decent', 0.6346985101699829),\n",
       " ('terrific', 0.6300877332687378),\n",
       " ('wonderful', 0.6222761869430542),\n",
       " ('perfect', 0.6207687854766846)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63198"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total vocabulary created \n",
    "len(wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63198"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of words and vectors to plug into vectorizer pipeline\n",
    "w2v = dict(zip(wv.index2word, wv.vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word vectors with a total vocabulary of 63198 has been created. We can check to see how well model is by checking similar words found by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feel': ['feeling', 'squeeze', 'material', 'structure', 'construction'],\n",
       " 'good': ['decent', 'great', 'excellent', 'ok', 'well'],\n",
       " 'product': ['item', 'company', 'seller', 'supplier', 'vendor'],\n",
       " 'cheap': ['cheaply', 'expensive', 'cheep', 'cheapo', 'flimsy'],\n",
       " 'bad': ['terrible', 'horrible', 'ok', 'awful', 'poor'],\n",
       " 'great': ['good', 'excellent', 'fantastic', 'awesome', 'nice'],\n",
       " 'price': ['cost', 'dollar', 'pricing', 'value', 'msrp']}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing w2v model by checking simlar word groupings\n",
    "\n",
    "sample = ['feel', 'good', 'product', 'cheap', 'bad', 'great','price']\n",
    "\n",
    "# loop through sample list and grab the top 5 most similar words\n",
    "similar_words = {word: [item[0] for item in wv.most_similar([word], topn=5)]\n",
    "                  for word in sample}\n",
    "similar_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concatenate sample and similar words\n",
    "labels = sum([[k] + v for k, v in similar_words.items()], [])\n",
    "\n",
    "# get vectors of all words\n",
    "vec = wv[labels]\n",
    "\n",
    "# reduce dimensionality of vectors to plot them\n",
    "tsne = TSNE(n_components=2, random_state=0, n_iter=10000, perplexity=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = tsne.fit_transform(vec)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "\n",
    "ax.scatter(T[:, 0], T[:, 1], c='orange')\n",
    "\n",
    "# label points\n",
    "for label, x, yt in zip(labels, T[:, 0], T[:, 1]):\n",
    "    ax.annotate(label, xy=(x+1, yt+1), xytext=(0, 0), textcoords='offset points', fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectors created by w2v looks sensible. Words from our similar words search group together and are distinct from other groupings. Words similar to good are far away from words similar to bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Word embeddings\n",
    "\n",
    "To make use of these individual word vectors for classification, we can compute the mean word embedding for each document. Basically we can take all the vectors represented by each word in a document and average them together in one single vector representing the document. This can help reduce dimensionality of features and make algorithms faster to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # Takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(w2v))])\n",
    "    \n",
    "    # Note: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "    # it can't be used in a scikit-learn pipeline  \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes does not take negative values for input, which some vectors created will have. I will skip MNB() classifer for these next steps to save some time on my part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mean f1_score</th>\n",
       "      <th>std f1_score</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_logr_model</td>\n",
       "      <td>0.9248</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.9145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_mnb_model</td>\n",
       "      <td>0.9173</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>0.9026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w2v_logr_model</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>0.8275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  mean f1_score  std f1_score  mean precision  mean recall\n",
       "0   cv_logr_model         0.9248        0.0016          0.9352       0.9145\n",
       "1    cv_mnb_model         0.9173        0.0012          0.9325       0.9026\n",
       "2  w2v_logr_model         0.8810        0.0015          0.9418       0.8275"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_logr_model = Pipeline([\n",
    "    ('w2v', W2vVectorizer(w2v)),\n",
    "    ('logr', logr)\n",
    "])\n",
    "\n",
    "w2v_logr = cross_validate(w2v_logr_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])\n",
    "\n",
    "model_results = model_results.append({'Model': 'w2v_logr_model',\n",
    "                      'mean f1_score': round(w2v_logr['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(w2v_logr['test_f1'].std(), 4),\n",
    "                      'mean precision': round(w2v_logr['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(w2v_logr['test_recall'].mean(), 4)}, ignore_index = True)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_logr_hat = cross_val_predict(w2v_logr_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, w2v_logr_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mean f1_score</th>\n",
       "      <th>std f1_score</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_logreg_model</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_mnb_model</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv_rf_model</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_logreg_model</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.8681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_mnb_model</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_rf_model</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.9894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>w2v_logr_model</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w2v_rf_model</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.9742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  mean f1_score  std f1_score  mean precision  \\\n",
       "0     cv_logreg_model         0.9073        0.0019          0.9371   \n",
       "1        cv_mnb_model         0.9164        0.0017          0.8980   \n",
       "2         cv_rf_model         0.9103        0.0007          0.8421   \n",
       "3  tfidf_logreg_model         0.9055        0.0021          0.9463   \n",
       "4     tfidf_mnb_model         0.8748        0.0003          0.7778   \n",
       "5      tfidf_rf_model         0.9109        0.0003          0.8440   \n",
       "6      w2v_logr_model         0.8806        0.0010          0.9413   \n",
       "7        w2v_rf_model         0.9077        0.0008          0.8496   \n",
       "\n",
       "   mean recall  \n",
       "0       0.8794  \n",
       "1       0.9355  \n",
       "2       0.9904  \n",
       "3       0.8681  \n",
       "4       0.9993  \n",
       "5       0.9894  \n",
       "6       0.8273  \n",
       "7       0.9742  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_w2v_model = Pipeline([\n",
    "    ('w2v', W2vVectorizer(w2v)),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "w2v_rf = cross_validate(rfc_w2v_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])\n",
    "\n",
    "model_results = model_results.append({'Model': 'w2v_rf_model',\n",
    "                      'mean f1_score': round(w2v_rf['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(w2v_rf['test_f1'].std(), 4),\n",
    "                      'mean precision': round(w2v_rf['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(w2v_rf['test_recall'].mean(), 4)}, ignore_index = True)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_rf_hat = cross_val_predict(w2v_rf_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, w2v_rf_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained word vectors with GloVe\n",
    "\n",
    "Instead of training word embeddings, we can make use of weights from models that have been trained on massive amounts of text data. One popular model is GloVe, which has been trained on text data from wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total vocabulary of train set\n",
    "total_vocabulary = set(word for review in X_train for word in review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get appropriate vectors from GloVe file, using 100 dimension vectors\n",
    "glove = {}\n",
    "with open('data/glove.6B.100d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.013786 ,  0.38216  ,  0.53236  ,  0.15261  , -0.29694  ,\n",
       "       -0.20558  , -0.41846  , -0.58437  , -0.77355  , -0.87866  ,\n",
       "       -0.37858  , -0.18516  , -0.128    , -0.20584  , -0.22925  ,\n",
       "       -0.42599  ,  0.3725   ,  0.26077  , -1.0702   ,  0.62916  ,\n",
       "       -0.091469 ,  0.70348  , -0.4973   , -0.77691  ,  0.66045  ,\n",
       "        0.09465  , -0.44893  ,  0.018917 ,  0.33146  , -0.35022  ,\n",
       "       -0.35789  ,  0.030313 ,  0.22253  , -0.23236  , -0.19719  ,\n",
       "       -0.0053125, -0.25848  ,  0.58081  , -0.10705  , -0.17845  ,\n",
       "       -0.16206  ,  0.087086 ,  0.63029  , -0.76649  ,  0.51619  ,\n",
       "        0.14073  ,  1.019    , -0.43136  ,  0.46138  , -0.43585  ,\n",
       "       -0.47568  ,  0.19226  ,  0.36065  ,  0.78987  ,  0.088945 ,\n",
       "       -2.7814   , -0.15366  ,  0.01015  ,  1.1798   ,  0.15168  ,\n",
       "       -0.050112 ,  1.2626   , -0.77527  ,  0.36031  ,  0.95761  ,\n",
       "       -0.11385  ,  0.28035  , -0.02591  ,  0.31246  , -0.15424  ,\n",
       "        0.3778   , -0.13599  ,  0.2946   , -0.31579  ,  0.42943  ,\n",
       "        0.086969 ,  0.019169 , -0.27242  , -0.31696  ,  0.37327  ,\n",
       "        0.61997  ,  0.13889  ,  0.17188  ,  0.30363  , -1.2776   ,\n",
       "        0.044423 , -0.52736  , -0.88536  , -0.19428  , -0.61947  ,\n",
       "       -0.10146  , -0.26301  , -0.061707 ,  0.36627  , -0.95223  ,\n",
       "       -0.39346  , -0.69183  , -1.0426   ,  0.28855  ,  0.63056  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['great']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26555"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_logr_model = Pipeline([\n",
    "    ('glove', W2vVectorizer(glove)),\n",
    "    ('logr', logr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "glove_logr = cross_validate(glove_logr_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append({'Model': 'glove_logr_model',\n",
    "                      'mean f1_score': round(glove_logr['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(glove_logr['test_f1'].std(), 4),\n",
    "                      'mean precision': round(glove_logr['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(glove_logr['test_recall'].mean(), 4)}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mean f1_score</th>\n",
       "      <th>std f1_score</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_logreg_model</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_mnb_model</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv_rf_model</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_logreg_model</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.8681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_mnb_model</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_rf_model</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.9894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>w2v_logr_model</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w2v_rf_model</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.9742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>glove_logr_model</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.7446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  mean f1_score  std f1_score  mean precision  \\\n",
       "0     cv_logreg_model         0.9073        0.0019          0.9371   \n",
       "1        cv_mnb_model         0.9164        0.0017          0.8980   \n",
       "2         cv_rf_model         0.9103        0.0007          0.8421   \n",
       "3  tfidf_logreg_model         0.9055        0.0021          0.9463   \n",
       "4     tfidf_mnb_model         0.8748        0.0003          0.7778   \n",
       "5      tfidf_rf_model         0.9109        0.0003          0.8440   \n",
       "6      w2v_logr_model         0.8806        0.0010          0.9413   \n",
       "7        w2v_rf_model         0.9077        0.0008          0.8496   \n",
       "8    glove_logr_model         0.8211        0.0017          0.9151   \n",
       "\n",
       "   mean recall  \n",
       "0       0.8794  \n",
       "1       0.9355  \n",
       "2       0.9904  \n",
       "3       0.8681  \n",
       "4       0.9993  \n",
       "5       0.9894  \n",
       "6       0.8273  \n",
       "7       0.9742  \n",
       "8       0.7446  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_logr_hat = cross_val_predict(glove_logr_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, glove_logr_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>mean f1_score</th>\n",
       "      <th>std f1_score</th>\n",
       "      <th>mean precision</th>\n",
       "      <th>mean recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_logreg_model</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_mnb_model</td>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv_rf_model</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf_logreg_model</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.8681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf_mnb_model</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tfidf_rf_model</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.9894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>w2v_logr_model</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.8273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w2v_rf_model</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.9742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>glove_logr_model</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.7446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>glove_rf_model</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.9839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  mean f1_score  std f1_score  mean precision  \\\n",
       "0     cv_logreg_model         0.9073        0.0019          0.9371   \n",
       "1        cv_mnb_model         0.9164        0.0017          0.8980   \n",
       "2         cv_rf_model         0.9103        0.0007          0.8421   \n",
       "3  tfidf_logreg_model         0.9055        0.0021          0.9463   \n",
       "4     tfidf_mnb_model         0.8748        0.0003          0.7778   \n",
       "5      tfidf_rf_model         0.9109        0.0003          0.8440   \n",
       "6      w2v_logr_model         0.8806        0.0010          0.9413   \n",
       "7        w2v_rf_model         0.9077        0.0008          0.8496   \n",
       "8    glove_logr_model         0.8211        0.0017          0.9151   \n",
       "9      glove_rf_model         0.8880        0.0002          0.8091   \n",
       "\n",
       "   mean recall  \n",
       "0       0.8794  \n",
       "1       0.9355  \n",
       "2       0.9904  \n",
       "3       0.8681  \n",
       "4       0.9993  \n",
       "5       0.9894  \n",
       "6       0.8273  \n",
       "7       0.9742  \n",
       "8       0.7446  \n",
       "9       0.9839  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_rf_model = Pipeline([\n",
    "    ('glove',  W2vVectorizer(glove)),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "glove_rf = cross_validate(glove_rf_model, X_train, y_train, cv = 5, scoring = ['precision', 'recall', 'f1'])\n",
    "\n",
    "\n",
    "\n",
    "model_results = model_results.append({'Model': 'glove_rf_model',\n",
    "                      'mean f1_score': round(glove_rf['test_f1'].mean(), 4),\n",
    "                      'std f1_score': round(glove_rf['test_f1'].std(), 4),\n",
    "                      'mean precision': round(glove_rf['test_precision'].mean(), 4),\n",
    "                      'mean recall': round(glove_rf['test_recall'].mean(), 4)}, ignore_index = True)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_rf_hat = cross_val_predict(glove_rf_model, X_train, y_train, cv = 5)\n",
    "cm = confusion_matrix(y_train, glove_rf_hat)\n",
    "f = sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
